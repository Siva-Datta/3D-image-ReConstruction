{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Model\n",
    "Use one of the model files in the models directory as model.py (default to mobilenetV2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "Base model loaded\n",
      "\n",
      "Model created.\n"
     ]
    }
   ],
   "source": [
    "from model import DepthEstimate\n",
    "model = DepthEstimate()                   \n",
    "batch_size     = 16                       \n",
    "learning_rate  = 0.0001\n",
    "epochs         = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def depth_loss_function(y_true, y_pred, theta=0.3, maxDepthVal=1000.0/10.0):\n",
    "    \n",
    "    # Point-wise depth\n",
    "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "    # Structural similarity (SSIM) index\n",
    "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
    "\n",
    "    # Weights\n",
    "    w1 = 1.0\n",
    "    w3 = theta\n",
    "\n",
    "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "#from loss import depth_loss_function   \n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(lr=learning_rate, amsgrad=True)\n",
    "\n",
    "model.compile(loss=depth_loss_function, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loading weights\n",
    " Load weights available in the google drive corresponding to the model loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f219939d350>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"~/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the DepthMap\n",
    "Output is saved as out.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "# Read Images \n",
    "rgb = mpimg.imread('/path-to-input-image/')  # Load input image\n",
    "rgb = rgb.resize((480,640))   #Resize Input image to 480x640\n",
    "# Output Images \n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import time\n",
    "import matplotlib\n",
    "a    = time.time()\n",
    "img1 = rgb\n",
    "img1 = img1.astype('float32')\n",
    "out = predict(model,img1,10.0,1000.0)\n",
    "out = out.reshape(240,320)\n",
    "out = scipy.ndimage.zoom(out, 2, order=1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(out)\n",
    "plt.show()\n",
    "matplotlib.image.imsave(\"~/out.png\",out,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation \n",
    "We used the gluoncv library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluoncv --upgrade\n",
    "!pip install -U --pre mxnet -f https://dist.mxnet.io/python/mkl\n",
    "# if cuda 10.1 is installed\n",
    "!pip install -U --pre mxnet -f https://dist.mxnet.io/python/cu100mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "import gluoncv\n",
    "img = image.imread('path to input image')\n",
    "# using cpu\n",
    "ctx = mx.cpu(0)\n",
    "\n",
    "from gluoncv.data.transforms.presets.segmentation import test_transform\n",
    "img = test_transform(img, ctx)\n",
    "\n",
    "model = gluoncv.model_zoo.get_model('deeplab_resnet101_ade', pretrained=True)\n",
    "output = model.predict(img)\n",
    "predict = mx.nd.squeeze(mx.nd.argmax(output, 1)).asnumpy()\n",
    "plt.imshow(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copying the depthmap to out1\n",
    "\n",
    "Taking minimum of the depths (min_depth) that are outside the segemtation area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#seg=np.clip(predict,np.mean(predict),np.max(predict))\n",
    "#seg = predict < np.mean(predict) \n",
    "min_depth = np.max(out)\n",
    "avg = np.mean(predict)\n",
    "for i in range(len(predict)):\n",
    "    for j in range(len(predict[0])):\n",
    "        out1[i][j] = out[i][j]\n",
    "        if predict[i][j]<avg:\n",
    "            if out[i][j]<min_depth:\n",
    "                min_depth=out[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixles inside the segmented area are divided by a certain factor to separate them from background and give a pop effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predict)):\n",
    "    for j in range(len(predict[0])):\n",
    "        if predict[i][j]>avg:\n",
    "                out1[i][j]= out1[i][j]/1.25\n",
    "        else:\n",
    "            out1[i][j]=out[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can Also push all the pixels in the segmented area to \"min_depth\" to get the average-3D mode as discussed in demo (Please refer to 3D demo directory under Demos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGB + DepthMap to PointClouds\n",
    "We are using the open3d library here.\n",
    "Final pointcloud is saved as pcd.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "out1=out1.astype('float32')\n",
    "color = o3d.geometry.Image(rgb)                                   \n",
    "depth = o3d.geometry.Image(out1)\n",
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color, depth,convert_rgb_to_intensity=False)\n",
    "print(rgbd_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('RGB image')\n",
    "plt.imshow(rgbd_image.color)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('depth image')\n",
    "plt.imshow(rgbd_image.depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        rgbd_image,\n",
    "        o3d.camera.PinholeCameraIntrinsic(\n",
    "            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n",
    "\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "o3d.io.write_point_cloud(\"~/pcd.ply\", pcd)\n",
    "o3d.visualization.draw_geometries([pcd],window_name='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
