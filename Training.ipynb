{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mobilefull\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/mobilefull/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/mobilefull'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 2s 0us/step\n",
      "Base model loaded\n",
      "\n",
      "Model created.\n"
     ]
    }
   ],
   "source": [
    "from model import DepthEstimate\n",
    "model = DepthEstimate()\n",
    "batch_size     = 16\n",
    "\n",
    "learning_rate  = 0.0001\n",
    "epochs         = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, csv_file='data/nyu2_train.csv', DEBUG=False):\n",
    "        self.shape_rgb = (480,640, 3)\n",
    "        self.shape_depth = (240,320, 1)\n",
    "        self.read_nyu_data(csv_file, DEBUG=DEBUG)\n",
    "\n",
    "    def nyu_resize(self, img, resolution=224, padding=6):\n",
    "        from skimage.transform import resize\n",
    "        return resize(img, (resolution, resolution), preserve_range=True, mode='reflect', anti_aliasing=True )\n",
    "\n",
    "    def read_nyu_data(self, csv_file, DEBUG=False):\n",
    "        csv = open(csv_file, 'r').read()\n",
    "        nyu2_train = list((row.split(',') for row in (csv).split('\\n') if len(row) > 0))\n",
    "\n",
    "        # Dataset shuffling happens here\n",
    "        nyu2_train = shuffle(nyu2_train, random_state=0)\n",
    "\n",
    "        # Test on a smaller dataset\n",
    "        if DEBUG: nyu2_train = nyu2_train[:10]\n",
    "        \n",
    "        # A vector of RGB filenames.\n",
    "        self.filenames = [i[0] for i in nyu2_train]\n",
    "\n",
    "        # A vector of depth filenames.\n",
    "        self.labels = [i[1] for i in nyu2_train]\n",
    "\n",
    "        # Length of dataset\n",
    "        self.length = len(self.filenames)\n",
    "\n",
    "    def _parse_function(self, filename, label): \n",
    "        # Read images from disk\n",
    "        #image_decoded = tf.image.decode_jpeg(tf.io.read_file(filename))\n",
    "        depth_resized = tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(label)), [self.shape_depth[0], self.shape_depth[1]])\n",
    "        image_decoded = tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(filename)), [self.shape_rgb[0], self.shape_rgb[1]])\n",
    "        # Format\n",
    "        rgb = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
    "        depth = tf.image.convert_image_dtype(depth_resized / 255.0, dtype=tf.float32)\n",
    "        \n",
    "        # Normalize the depth values (in cm)\n",
    "        depth = 1000 / tf.clip_by_value(depth * 1000, 10, 1000)\n",
    "\n",
    "        return rgb, depth\n",
    "\n",
    "    def get_batched_dataset(self, batch_size):\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.filenames, self.labels))\n",
    "        self.dataset = self.dataset.shuffle(buffer_size=len(self.filenames), reshuffle_each_iteration=True)\n",
    "        self.dataset = self.dataset.repeat()\n",
    "        self.dataset = self.dataset.map(map_func=self._parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        #self.dataset = self.dataset.map(map_func=self.nyu_resize)\n",
    "        self.dataset = self.dataset.batch(batch_size=batch_size)\n",
    "\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/extract\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader ready.\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader()\n",
    "train_generator = dl.get_batched_dataset(batch_size)\n",
    "\n",
    "print('Data loader ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def depth_loss_function(y_true, y_pred, theta=0.1, maxDepthVal=1000.0/10.0):\n",
    "    \n",
    "    # Point-wise depth\n",
    "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "    # Edges\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
    "\n",
    "    # Structural similarity (SSIM) index\n",
    "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
    "\n",
    "    # Weights\n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    w3 = theta\n",
    "\n",
    "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "#from loss import depth_loss_function\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(lr=learning_rate, amsgrad=True)\n",
    "\n",
    "model.compile(loss=depth_loss_function, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/test-data\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded.\n",
      "\n",
      "(654, 480, 640, 3)\n",
      "(654, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from io import BytesIO\n",
    "rgb = np.load('eigen_test_rgb.npy')\n",
    "depth = np.load('eigen_test_depth.npy')\n",
    "crop = np.load('eigen_test_crop.npy')\n",
    "print('Test data loaded.\\n')\n",
    "print(np.shape(rgb))\n",
    "print(np.shape(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/evaluateutils\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/evaluateutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import predict, load_images, display_images, evaluate\n",
    "class ev_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    b=time.time()\n",
    "    e = evaluate(model, rgb, depth, crop, batch_size=1)\n",
    "    print(\"eval results \")\n",
    "    print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
    "    print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
    "    print(\"eval time...\")\n",
    "    print(time.time()-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/extract\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3168 steps\n",
      "Epoch 1/6\n",
      "3167/3168 [============================>.] - ETA: 0s - loss: 0.1682\n",
      "Epoch 00001: saving model to /kaggle/working/training_mob_bs16/cp.ckpt\n",
      "eval results \n",
      "        a1,         a2,         a3,        rel,        rms,     log_10\n",
      "    0.2811,     0.5434,     0.7586,     0.6576,     1.6815,     0.2015\n",
      "eval time...\n",
      "162.74237823486328\n",
      "3168/3168 [==============================] - 2761s 871ms/step - loss: 0.1682\n",
      "Epoch 2/6\n",
      "3167/3168 [============================>.] - ETA: 0s - loss: 0.1139\n",
      "Epoch 00002: saving model to /kaggle/working/training_mob_bs16/cp.ckpt\n",
      "eval results \n",
      "        a1,         a2,         a3,        rel,        rms,     log_10\n",
      "    0.3185,     0.6243,     0.8197,     0.5413,     1.5616,     0.1777\n",
      "eval time...\n",
      "148.99979305267334\n",
      "3168/3168 [==============================] - 2702s 853ms/step - loss: 0.1139\n",
      "Epoch 3/6\n",
      "3167/3168 [============================>.] - ETA: 0s - loss: 0.1014\n",
      "Epoch 00003: saving model to /kaggle/working/training_mob_bs16/cp.ckpt\n",
      "eval results \n",
      "        a1,         a2,         a3,        rel,        rms,     log_10\n",
      "    0.2427,     0.4820,     0.7045,     0.7680,     1.7702,     0.2227\n",
      "eval time...\n",
      "173.87130975723267\n",
      "3168/3168 [==============================] - 2724s 860ms/step - loss: 0.1014\n",
      "Epoch 4/6\n",
      "3167/3168 [============================>.] - ETA: 0s - loss: 0.0947\n",
      "Epoch 00004: saving model to /kaggle/working/training_mob_bs16/cp.ckpt\n",
      "eval results \n",
      "        a1,         a2,         a3,        rel,        rms,     log_10\n",
      "    0.4022,     0.7135,     0.8800,     0.3771,     1.3273,     0.1476\n",
      "eval time...\n",
      "162.4359667301178\n",
      "3168/3168 [==============================] - 2700s 852ms/step - loss: 0.0947\n",
      "Epoch 5/6\n",
      "3167/3168 [============================>.] - ETA: 0s - loss: 0.0896\n",
      "Epoch 00005: saving model to /kaggle/working/training_mob_bs16/cp.ckpt\n",
      "eval results \n",
      "        a1,         a2,         a3,        rel,        rms,     log_10\n",
      "    0.3784,     0.6700,     0.8417,     0.4237,     1.4262,     0.1609\n",
      "eval time...\n",
      "152.0691487789154\n",
      "3168/3168 [==============================] - 2706s 854ms/step - loss: 0.0896\n",
      "Epoch 6/6\n",
      "3167/3168 [============================>.] - ETA: 0s - loss: 0.0863\n",
      "Epoch 00006: saving model to /kaggle/working/training_mob_bs16/cp.ckpt\n",
      "eval results \n",
      "        a1,         a2,         a3,        rel,        rms,     log_10\n",
      "    0.3991,     0.6837,     0.8530,     0.3878,     1.3718,     0.1554\n",
      "eval time...\n",
      "182.84980964660645\n",
      "3168/3168 [==============================] - 2729s 861ms/step - loss: 0.0863\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "checkpoint_path = \"/kaggle/working/training_mob_bs16/cp.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tensorflow.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
    "import time\n",
    "a=time.time()\n",
    "history=model.fit(train_generator, epochs=epochs, steps_per_epoch=dl.length//batch_size, callbacks=[cp_callback,ev_callback()],initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
