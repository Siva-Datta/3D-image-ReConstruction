{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "WtqQl39p52EF"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "id": "dJNXOD0bJA4o",
    "outputId": "85524442-74de-4a29-8274-a78a8bbf15ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "TF_INC: /usr/local/lib/python2.7/dist-packages/tensorflow_core/include\n",
      "TF_LIB: /usr/local/lib/python2.7/dist-packages/tensorflow_core\n",
      "TF_COMPILE_FLAGS: -I/usr/local/lib/python2.7/dist-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "TF_LINK_FLAGS: -L/usr/local/lib/python2.7/dist-packages/tensorflow_core -l:libtensorflow_framework.so.2\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for pthread_create\n",
      "-- Looking for pthread_create - not found\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found CUDA: /usr/local/cuda (found version \"10.1\") \n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/external/nsync/public/\n",
      "CMAKE_CXX_FLAGS: -std=c++11 -fPIC  -I/usr/local/lib/python2.7/dist-packages/tensorflow_core/include -D_GLIBCXX_USE_CXX11_ABI=0 -DGOOGLE_CUDA\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/drive/My Drive/bts/tensorflow/custom_layer\n"
     ]
    }
   ],
   "source": [
    "!cmake -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda  \"~/custom_layer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "colab_type": "code",
    "id": "neHxa4IUJXVI",
    "outputId": "3f4d0ba8-9c02-4c59-debd-111af15ef55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-33%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/lpg.dir/lpg_generated_local_planar_guidance.cu.o\u001b[0m\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/absl/strings/string_view.h(495): warning: expression has no effect\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/tensorflow/core/platform/env.h(356): warning: overloaded virtual function \"tensorflow::Env::RegisterFileSystem\" is only partially overridden in class \"tensorflow::EnvWrapper\"\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/absl/types/optional.h(425): warning: expression has no effect\n",
      "          detected during instantiation of \"const T &absl::optional<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]\" \n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.h(804): here\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/absl/types/optional.h(425): warning: expression has no effect\n",
      "          detected during instantiation of \"const T &absl::optional<T>::operator*() const & [with T=size_t]\" \n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.h(858): here\n",
      "\n",
      "/content/drive/My Drive/bts/tensorflow/custom_layer/local_planar_guidance.cu(56): warning: variable \"fo\" was declared but never referenced\n",
      "\n",
      "/content/drive/My Drive/bts/tensorflow/custom_layer/local_planar_guidance.cu(124): warning: variable \"n4\" was declared but never referenced\n",
      "\n",
      "/content/drive/My Drive/bts/tensorflow/custom_layer/local_planar_guidance.cu(126): warning: variable \"fo\" was declared but never referenced\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/absl/strings/string_view.h(495): warning: expression has no effect\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/tensorflow/core/platform/env.h(356): warning: overloaded virtual function \"tensorflow::Env::RegisterFileSystem\" is only partially overridden in class \"tensorflow::EnvWrapper\"\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/absl/types/optional.h(425): warning: expression has no effect\n",
      "          detected during instantiation of \"const T &absl::optional<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]\" \n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.h(804): here\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/absl/types/optional.h(425): warning: expression has no effect\n",
      "          detected during instantiation of \"const T &absl::optional<T>::operator*() const & [with T=size_t]\" \n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow_core/include/tensorflow/stream_executor/dnn.h(858): here\n",
      "\n",
      "\u001b[35m\u001b[1mScanning dependencies of target lpg\u001b[0m\n",
      "[  0%] \u001b[32mBuilding CXX object CMakeFiles/lpg.dir/local_planar_guidance.cc.o\u001b[0m\n",
      "[ 33%] \u001b[32m\u001b[1mLinking CXX shared library liblpg.so\u001b[0m\n",
      "[ 33%] Built target lpg\n"
     ]
    }
   ],
   "source": [
    "!make -j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "WNwlxw9T52Fd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, LeakyReLU, Concatenate, BatchNormalization\n",
    "import tensorflow as tf\n",
    "\n",
    "import _local_planar_guidance_grad\n",
    "lpg = tf.load_op_library('~/custom_layer/liblpg.so')\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.base_model = MobileNetV2(input_shape=(480,640, 3), include_top=False, weights='imagenet')\n",
    "        print('Base model loaded')\n",
    "\n",
    "        outputs = [self.base_model.outputs[-1]]\n",
    "        for name in ['block_1_expand_relu','block_3_expand_relu','block_6_expand_relu','block_13_expand_relu','block_16_expand_relu'] : outputs.append( self.base_model.get_layer(name).output )\n",
    "        self.encoder = Model(inputs=self.base_model.inputs, outputs=outputs)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class ConvBlock(Model):\n",
    "    def __init__(self, num_out_layers, kernel_size,stride, activation_fn):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.convA = Conv2D(filters=num_out_layers, kernel_size=kernel_size,strides=stride,padding='valid', activation=activation_fn)\n",
    "    \n",
    "    def call(self, x, kernel_size):\n",
    "        p = np.floor((kernel_size - 1) / 2).astype(np.int32)\n",
    "        p_x = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]])\n",
    "        return self.convA(p_x)\n",
    "\n",
    "\n",
    "class UpConv(Model):\n",
    "    def __init__(self,num_filters, kernel_size, stride, activation_fn):\n",
    "        super(UpConv, self).__init__()\n",
    "        #self.up1 = ConvBlock(num_filters, kernel_size, stride, tf.nn.elu)\n",
    "\n",
    "    def call(self, x, kernel_size):\n",
    "        \n",
    "        upsample = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        #conv1 = self.up1(upsample, kernel_size)\n",
    "        #print(conv1)\n",
    "        return upsample\n",
    "\n",
    "class BatchNorm(Model):\n",
    "\n",
    "    def __init__(self,momentum,epsilon):\n",
    "        super(BatchNorm,self).__init__()\n",
    "        self.bn=BatchNormalization(momentum=momentum, epsilon=epsilon,scale=True,fused=True, trainable=True)\n",
    "\n",
    "    def call(self,x):\n",
    "        return self.bn(x)\n",
    "\n",
    "\n",
    "class AtrConv(Model):\n",
    "\n",
    "    def __init__(self,num_out_layers, kernel_size,rate):\n",
    "        super(AtrConv,self).__init__()\n",
    "        self.bn1  = BatchNorm(momentum=0.99, epsilon=1.1e-5)\n",
    "        self.con1 = Conv2D(num_out_layers * 2, 1, 1, 'same')\n",
    "        self.bn2  = BatchNorm(momentum=0.99, epsilon=1.1e-5)\n",
    "        self.con2 = Conv2D(num_out_layers, kernel_size=kernel_size,dilation_rate=rate, strides=1, padding='same',activation=None)\n",
    "    \n",
    "    def call(self,out,apply_bn_first = True) :\n",
    "\n",
    "        if apply_bn_first is True:\n",
    "            out = self.bn1(out)\n",
    "\n",
    "        out   = tf.nn.relu(out)\n",
    "        out   = self.con1(out)\n",
    "        out   = self.bn2(out)\n",
    "        out   = tf.nn.relu(out)\n",
    "        out   = self.con2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class R1x1(Model):\n",
    "\n",
    "    def __init__(self,num_filters):\n",
    "        super(R1x1,self).__init__()\n",
    "        self.convA = ConvBlock(1,1,1,tf.nn.sigmoid)\n",
    "        self.convB = ConvBlock(3,1,1,None)\n",
    "        self.convC = ConvBlock(num_filters, 1, 1,tf.nn.relu)\n",
    "    def call(self,net,num_filters,is_final=False):\n",
    "        while num_filters >= 4:\n",
    "            if num_filters < 8:\n",
    "                if is_final:\n",
    "                    net = self.convA(net,1)\n",
    "                else:\n",
    "                    net = self.convB(net, 3)\n",
    "                    theta = tf.nn.sigmoid(net[:, :, :, 0]) * 3.1415926535 / 6\n",
    "                    phi = tf.nn.sigmoid(net[:, :, :, 1]) * 3.1415926535 * 2\n",
    "                    dist = tf.nn.sigmoid(net[:, :, :, 2]) * 10\n",
    "                    n1 = tf.expand_dims(tf.multiply(tf.math.sin(theta), tf.math.cos(phi)), 3)\n",
    "                    n2 = tf.expand_dims(tf.multiply(tf.math.sin(theta), tf.math.sin(phi)), 3)\n",
    "                    n3 = tf.expand_dims(tf.math.cos(theta), 3)\n",
    "                    n4 = tf.expand_dims(dist, 3)\n",
    "                    net = tf.concat([n1, n2, n3, n4], axis=3)\n",
    "                break\n",
    "            else:\n",
    "                net = self.convC(net, 1)\n",
    "\n",
    "            num_filters = num_filters // 2\n",
    "\n",
    "        return net\n",
    "\n",
    "   \n",
    "class Decoder(Model):\n",
    "    def __init__(self, num_filters):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.max_depth = 10\n",
    "        self.focal = 519\n",
    "\n",
    "        self.upconA = UpConv(num_filters, 3, 2, tf.nn.elu) #\n",
    "        self.upconB = UpConv(num_filters //2 , 3, 2, tf.nn.elu) #\n",
    "        self.upconC = UpConv(num_filters //4 , 3, 2, tf.nn.elu)  #\n",
    "        self.upconD = UpConv(num_filters //8 , 3, 2, tf.nn.elu)  #\n",
    "               \n",
    "        self.conA   = ConvBlock(num_filters,3,1,tf.nn.elu)#\n",
    "        self.conB   = ConvBlock(num_filters // 2 , 3,1,tf.nn.elu)#\n",
    "        self.conC   = ConvBlock(num_filters //4 ,3,1,tf.nn.elu)#\n",
    "        self.conD   = ConvBlock(num_filters // 4 ,3,1,tf.nn.elu)#\n",
    "        self.conE   = ConvBlock(num_filters // 8 ,3,1,tf.nn.elu)#\n",
    "        self.conE   = ConvBlock(num_filters // 16 ,3,1,tf.nn.elu)#\n",
    "               \n",
    "        self.bnA    = BatchNorm(momentum=0.99, epsilon=1.1e-5)#\n",
    "        self.bnB    = BatchNorm(momentum=0.99, epsilon=1.1e-5)#\n",
    "        self.bnC    = BatchNorm(momentum=0.99, epsilon=1.1e-5)#\n",
    "        self.bnD    = BatchNorm(momentum=0.99, epsilon=1.1e-5)#\n",
    "        self.bnE    = BatchNorm(momentum=0.99, epsilon=1.1e-5)#\n",
    "        \n",
    "        self.atA    = AtrConv(num_filters // 4  ,3, 3 ) #\n",
    "        self.atB    = AtrConv(num_filters //4 , 3, 6 ) #\n",
    "        self.atC    = AtrConv(num_filters //4 , 3, 12) #\n",
    "        self.atD    = AtrConv(num_filters // 4  ,3, 18 ) #\n",
    "        self.atE    = AtrConv(num_filters // 4  ,3, 24 ) #\n",
    "        \n",
    "        self.r11A   = R1x1 (num_filters // 4)#\n",
    "        self.r11B   = R1x1 (num_filters // 8)#\n",
    "       \n",
    "\n",
    "    \n",
    "    def downsample_nn(self, x, ratio):\n",
    "        s = tf.shape(x)\n",
    "        h = tf.cast(s[1] / ratio, tf.int32)\n",
    "        w = tf.cast(s[2] / ratio, tf.int32)\n",
    "        return tf.image.resize(x, [h, w])\n",
    "    \n",
    "    def call(self, features):\n",
    "        x,d1,d2,d3,d4,d5= features[0], features[1], features[2], features[3], features[4], features[5]\n",
    "\n",
    "        num_filters = 640\n",
    "        max_depth = 10\n",
    "    \n",
    "        upconv5 = self.upconA(x,3)  # H/16\n",
    "        upconv5 = self.bnA(upconv5)\n",
    "        \n",
    "        concat5 = tf.concat([upconv5,d4], 3)\n",
    "        iconv5 = self.conA(concat5, 3)\n",
    "        num_filters = num_filters // 2\n",
    "\n",
    "        upconv4 = self.upconB(iconv5, 3)  # H/8\n",
    "        upconv4 = self.bnB(upconv4)\n",
    "        \n",
    "        concat4 = tf.concat([upconv4,d3], 3)\n",
    "        iconv4 = self.conB(concat4, 3)\n",
    "        \n",
    "        iconv4 = self.bnC(iconv4)\n",
    "        daspp_3 = self.atA(iconv4, apply_bn_first=False)\n",
    "        concat4_2 = tf.concat([concat4, iconv4], 3)\n",
    "        \n",
    "        daspp_6 = self.atB(concat4_2)\n",
    "        concat4_3 = tf.concat([concat4_2, daspp_6], 3)\n",
    "        daspp_12 = self.atC(concat4_3)\n",
    "        concat4_4 = tf.concat([concat4_3, daspp_12], 3)\n",
    "        \n",
    "        daspp_18 = self.atD(concat4_4)\n",
    "        concat4_5 = tf.concat([concat4_4, daspp_18], 3)\n",
    "        \n",
    "        daspp_24 = self.atE(concat4_5)\n",
    "        concat4_daspp = tf.concat([iconv4, daspp_3, daspp_6, daspp_12, daspp_18, daspp_24], 3)\n",
    "        \n",
    "        daspp_feat = self.conC(concat4_daspp,3)\n",
    "        \n",
    "        plane_eq_8x8 = self.r11A(daspp_feat, num_filters // 2)\n",
    "        plane_normal_8x8 = tf.nn.l2_normalize(plane_eq_8x8[:, :, :, 0:3], axis=3)\n",
    "        plane_dist_8x8 = plane_eq_8x8[:, :, :, 3]\n",
    "        plane_eq_8x8 = tf.concat([plane_normal_8x8, tf.expand_dims(plane_dist_8x8, 3)], 3)\n",
    "        depth_8x8 = lpg.local_planar_guidance(plane_eq_8x8, upratio=8, focal=self.focal)\n",
    "        depth_8x8_scaled = tf.expand_dims(depth_8x8, 3) / 10\n",
    "        depth_8x8_scaled_ds = self.downsample_nn(depth_8x8_scaled, 4)\n",
    "        \n",
    "        num_filters = num_filters // 2\n",
    "        \n",
    "        upconv3 = self.upconC(daspp_feat ,3)  # H/4\n",
    "        upconv3 = self.bnD(upconv3)\n",
    "        concat3 = tf.concat([upconv3,d2, depth_8x8_scaled_ds], 3)\n",
    "        #concat3 = tf.concat([upconv3,d2], 3)\n",
    "        iconv3 = self.conD(concat3, 3)\n",
    "        \n",
    "        plane_eq_4x4 = self.r11B(iconv3, num_filters // 2)\n",
    "        plane_normal_4x4 = tf.nn.l2_normalize(plane_eq_4x4[:, :, :, 0:3], axis=3)\n",
    "        plane_dist_4x4 = plane_eq_4x4[:, :, :, 3]\n",
    "        plane_eq_4x4 = tf.concat([plane_normal_4x4, tf.expand_dims(plane_dist_4x4, 3)], 3)\n",
    "        depth_4x4 = lpg.local_planar_guidance(plane_eq_4x4, upratio=4, focal=self.focal)\n",
    "        depth_4x4_scaled = tf.expand_dims(depth_4x4, 3) / 10\n",
    "        depth_4x4_scaled_ds = self.downsample_nn(depth_4x4_scaled, 2)\n",
    "\n",
    "        num_filters = num_filters // 2    #1/8\n",
    "\n",
    "        upconv2 = self.upconD(iconv3,  3)  # H/2\n",
    "        upconv2 = self.bnE(upconv2)\n",
    "        concat2 = tf.concat([upconv2, d1 , depth_4x4_scaled_ds], 3)\n",
    "        iconv2 = self.conE(concat2, 3)\n",
    "        \n",
    "        plane_eq_2x2 = self.reduction_1x1(iconv2, num_filters / 2)\n",
    "        plane_normal_2x2 = tf.nn.l2_normalize(plane_eq_2x2[:, :, :, 0:3], axis=3)\n",
    "        plane_dist_2x2 = plane_eq_2x2[:, :, :, 3]\n",
    "        plane_eq_2x2 = tf.concat([plane_normal_2x2, tf.expand_dims(plane_dist_2x2, 3)], 3)\n",
    "        depth_2x2 = lpg.local_planar_guidance(plane_eq_2x2, upratio=2, focal=self.focal)\n",
    "        depth_2x2_scaled = tf.expand_dims(depth_2x2, 3) / self.max_depth\n",
    "\n",
    "        num_filters = num_filters / 2\n",
    "\n",
    "        upconv1 = self.upconD(iconv2, 3)  # H\n",
    "        reduc1x1 = self.reduction_1x1(upconv1, num_filters, is_final=True)\n",
    "        concat1 = tf.concat([upconv1, reduc1x1, depth_2x2_scaled, depth_4x4_scaled, depth_8x8_scaled], 3)\n",
    "        iconv1 = self.conF(concat1, 3)\n",
    "        \n",
    "        \n",
    "        return iconv1\n",
    "\n",
    "class DepthEstimate(Model):\n",
    "    def __init__(self):\n",
    "        super(DepthEstimate, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder( num_filters = int(self.encoder.layers[-1].output[0].shape[-1] // 2 ) )\n",
    "        print('\\nModel created.')\n",
    "\n",
    "    def call(self, x):\n",
    "        p=self.encoder(x)\n",
    "        return self.decoder(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "90UQ-DbFlxRZ",
    "outputId": "1a2ec07e-c44a-47fd-cfc7-7f122512e537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "Base model loaded\n",
      "\n",
      "Model created.\n"
     ]
    }
   ],
   "source": [
    "model = DepthEstimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "68gJA5aC52Fj"
   },
   "outputs": [],
   "source": [
    "batch_size     = 1\n",
    "learning_rate  = 0.0001\n",
    "epochs         = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCYC1KsN52GE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, csv_file='data/nyu2_train.csv', DEBUG=False):\n",
    "        self.shape_rgb = (480,640, 3)\n",
    "        self.shape_depth = (480,640, 1)\n",
    "        self.read_nyu_data(csv_file, DEBUG=DEBUG)\n",
    "        \n",
    "    def read_nyu_data(self, csv_file, DEBUG=False):\n",
    "        csv = open(csv_file, 'r').read()\n",
    "        nyu2_train = list((row.split(',') for row in (csv).split('\\n') if len(row) > 0))\n",
    "        #nyu2_train=nyu2_train[0:100]\n",
    "        # Dataset shuffling happens here\n",
    "        nyu2_train = shuffle(nyu2_train, random_state=0)\n",
    "        nyu2_train=nyu2_train[1:10]\n",
    "        # Test on a smaller dataset\n",
    "        if DEBUG: nyu2_train = nyu2_train[:10]\n",
    "        \n",
    "        # A vector of RGB filenames.\n",
    "        self.filenames = [i[0] for i in nyu2_train]\n",
    "\n",
    "        # A vector of depth filenames.\n",
    "        self.labels = [i[1] for i in nyu2_train]\n",
    "\n",
    "        # Length of dataset\n",
    "        self.length = len(self.filenames)\n",
    "\n",
    "    def _parse_function(self, filename, label): \n",
    "        # Read images from disk\n",
    "        #image_decoded = tf.image.decode_jpeg(tf.io.read_file(filename))\n",
    "        depth_resized = tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(label)), [self.shape_depth[0], self.shape_depth[1]])\n",
    "        image_decoded = tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(filename)), [self.shape_rgb[0], self.shape_rgb[1]])\n",
    "        # Format\n",
    "        rgb = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
    "        depth = tf.image.convert_image_dtype(depth_resized / 255.0, dtype=tf.float32)\n",
    "        \n",
    "        # Normalize the depth values (in cm)\n",
    "        depth = 1000 / tf.clip_by_value(depth * 1000, 10, 1000)\n",
    "\n",
    "        return rgb, depth\n",
    "\n",
    "    def get_batched_dataset(self, batch_size):\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.filenames, self.labels))\n",
    "        self.dataset = self.dataset.shuffle(buffer_size=len(self.filenames), reshuffle_each_iteration=True)\n",
    "        self.dataset = self.dataset.repeat()\n",
    "        self.dataset = self.dataset.map(map_func=self._parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        #self.dataset = self.dataset.map(map_func=self.nyu_resize)\n",
    "        self.dataset = self.dataset.batch(batch_size=batch_size)\n",
    "\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEwQMHM552Fq"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "#from loss import depth_loss_function\n",
    "\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(lr=learning_rate, amsgrad=True)\n",
    "\n",
    "model.compile(loss=depth_loss_function, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uH86KKH52F1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "checkpoint_path = \"/content/drive/My Drive/workspace/btscp/cp.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tensorflow.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
    "import time\n",
    "a=time.time()\n",
    "history=model.fit(train_generator, epochs=1, steps_per_epoch=dl.length//batch_size, callbacks=[cp_callback],initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fdiGZ9PC52GJ",
    "outputId": "6cd6d5d2-d7ec-48d1-8d72-22137f5a39b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loader ready.\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader()\n",
    "train_generator = dl.get_batched_dataset(batch_size)\n",
    "\n",
    "print('Data loader ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "QQff6YjR52GS",
    "outputId": "23c8a425-568d-4806-851d-6e3aef9d5ccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef depth_loss_function(y_true, y_pred, theta=0.3, maxDepthVal=1000.0/10.0):\\n    \\n    # Point-wise depth\\n    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\\n\\n    # Edges\\n    dy_true, dx_true = tf.image.image_gradients(y_true)\\n    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\\n    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\\n\\n    # Structural similarity (SSIM) index\\n    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\\n\\n    # Weights\\n    w1 = 1.0\\n    w2 = 1.0\\n    w3 = theta\\n\\n    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow.keras.backend as K\n",
    "'''\n",
    "def depth_loss_function(y_true, y_pred, theta=0.3, maxDepthVal=1000.0/10.0):\n",
    "    \n",
    "    # Point-wise depth\n",
    "    l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "    # Edges\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "    l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)\n",
    "\n",
    "    # Structural similarity (SSIM) index\n",
    "    l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, maxDepthVal)) * 0.5, 0, 1)\n",
    "\n",
    "    # Weights\n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    w3 = theta\n",
    "\n",
    "    return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Glu6Eiui52GX"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def depth_loss_function(y_true, y_pred):\n",
    "    y_pred=tf.dtypes.cast(y_pred, tf.float32)\n",
    "    y_true=tf.dtypes.cast(y_true, tf.float32)\n",
    "    eps=0.0001\n",
    "    thresh=y_true>eps\n",
    "    y_tr = y_true[thresh] \n",
    "    y_pr = y_pred[thresh] \n",
    "    \n",
    "    logloss = K.mean( K.abs(K.log(y_tr) - K.log(y_pr)), axis=-1)\n",
    "    return  logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gq04_Fy652Gc"
   },
   "outputs": [],
   "source": [
    "cd /kaggle/input/test-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mmw3yh452Gh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import BytesIO\n",
    "rgb = np.load('eigen_test_rgb.npy')\n",
    "depth = np.load('eigen_test_depth.npy')\n",
    "crop = np.load('eigen_test_crop.npy')\n",
    "print('Test data loaded.\\n')\n",
    "print(np.shape(rgb))\n",
    "print(np.shape(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnPb0P4a52Gl"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from skimage.transform import resize\n",
    "import time\n",
    "rgb1=[]\n",
    "depth1=[]\n",
    "for i in range(len(rgb)):\n",
    "    rgb1.append(resize(rgb[i], (224,224), preserve_range=True, mode='reflect', anti_aliasing=True ))\n",
    "for j in range(len(depth)):\n",
    "    depth1.append(resize(depth[j], (224,224), preserve_range=True, mode='reflect', anti_aliasing=True ))\n",
    "start = time.time()\n",
    "print(np.shape(rgb1))\n",
    "print(np.shape(depth1))\n",
    "print('Testing...')\n",
    "rgb1=np.array(rgb1)\n",
    "depth1=np.array(depth1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Xe8-7tb52Gp"
   },
   "outputs": [],
   "source": [
    "cd /kaggle/input/evaluateutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECGKhOLn52Gv"
   },
   "outputs": [],
   "source": [
    "from utils import predict, load_images, display_images, evaluate\n",
    "class ev_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    b=time.time()\n",
    "    e = evaluate(model, rgb, depth, crop, batch_size=1)\n",
    "    print(\"eval results \")\n",
    "    print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
    "    print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
    "    print(\"eval time...\")\n",
    "    print(time.time()-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13lVNQ-E52Gz"
   },
   "outputs": [],
   "source": [
    "#model.load_weights(\"/kaggle/input/logloss4/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39VLTtxy52G3"
   },
   "outputs": [],
   "source": [
    "cd /kaggle/input/extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9GAGO9952G-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bts_tf2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
